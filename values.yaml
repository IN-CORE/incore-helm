# Default values for incore.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# what level is the server, this is used to read some config files
level: prod

replicaCount: 1

image:
  project: hub.ncsa.illinois.edu/incore
  pullPolicy: IfNotPresent
  pullSecrets:
    - name: regcred

imagePullSecrets:
  - name: regcred
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

# this will check for services if cors is allowed
cors:
  origin: []
  methods: GET,POST,DELETE
  headers: authorization

podAnnotations: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: true
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: incore.exmple.com
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local
  # should we add middleare annotations for traefik v2?
  traefik: false

# used by both data and hazard services
persistence:
  size: 10Gi
  #existingClaim: someclaim

# quotas for incore. there are 3 top level groups:
# - users, quotas for individual users
# - groups, quotas per group, weight is used to order
# - default quotas
# each quota will have:
# - cpu [min, max] for jupyterhub
# - mem [min, max] for jupyterhub
# - disk max total disk quota for user
# - service [number of objects, size] quota for each of the services
quota: |
  {
    "groups": {
       "incore_ncsa": {
         "weight": 1,
         "cpu": [ 1, 8 ],
         "mem": [ 2, 16 ],
         "disk": 100,
         "service": [ 200, 5 ]
       },
       "incore_coe": {
         "weight": 0,
         "cpu": [ 1, 4 ],
         "mem": [ 2, 8 ],
         "disk": 10,
         "service": [ 200, 5 ]
       }
     },
     "default": {
       "cpu": [ 1, 2 ],
       "mem": [ 2, 4 ],
       "disk": 4,
       "service": [ 100, 2 ]
     }
  }

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}

# ----------------------------------------------------------------------
# FRONTEND CONFIGURATION
# ----------------------------------------------------------------------
frontend:
  replicas: 1
  image:
    repository: frontend
    tag: 1.6.0
  service:
    type: ClusterIP
    port: 80
  ingress:
    annotations:
  persistence:
    size: 1Gi

# ----------------------------------------------------------------------
# AUTHENTICATION CONFIGURATION
# ----------------------------------------------------------------------
auth:
  replicas: 1
  realm: In-core
  audience: INCORE
  image:
    repository: incore-auth
    tag: 1.6.0
  service:
    type: ClusterIP
    port: 5000
  influxdb:
    url: "http://influxdb:8086/"
    org: "incore"
    location: "data/IP2LOCATION-LITE-DB5.BIN"
    token: ""
  persistence:
    size: 5Gi

# ----------------------------------------------------------------------
# INCORE DOCUMENTATION CONFIGURATION
# ----------------------------------------------------------------------
doc_incore:
  replicas: 1
  image:
    repository: doc/incore
    tag: 4.1.0
  service:
    type: ClusterIP
    port: 80

# ----------------------------------------------------------------------
# PYINCORE DOCUMENTATION CONFIGURATION
# ----------------------------------------------------------------------
doc_pyincore:
  replicas: 1
  image:
    repository: doc/pyincore
    tag: v1.10.0
  service:
    type: ClusterIP
    port: 80

# ----------------------------------------------------------------------
# PYINCORE_VIZ DOCUMENTATION CONFIGURATION
# ----------------------------------------------------------------------
doc_pyincore_viz:
  replicas: 1
  image:
    repository: doc/pyincore-viz
    tag: 1.8.1
  service:
    type: ClusterIP
    port: 80

# ----------------------------------------------------------------------
# PYINCORE_VIZ DOCUMENTATION CONFIGURATION
# ----------------------------------------------------------------------
doc_pyincore_data:
  replicas: 1
  image:
    repository: doc/pyincore-data
    tag: 0.6.0
  service:
    type: ClusterIP
    port: 80

# ----------------------------------------------------------------------
# API DOCUMENTATION CONFIGURATION
# ----------------------------------------------------------------------
doc_api:
  replicas: 1
  image:
    repository: doc/api
    tag: 1.13.0
  service:
    type: ClusterIP
    port: 80

# ----------------------------------------------------------------------
# DATA SERVICE CONFIGURATION
# ----------------------------------------------------------------------
svc_data:
  replicas: 4
  repo: /home/incore/data/
  image:
    repository: data-jetty
    tag: 1.13.2
  service:
    type: ClusterIP
    port: 8888
  ingress:
    annotations:
  geoserver:
    enabled: true
#      ingress.kubernetes.io/auth-url: /auth/
#      ingress.kubernetes.io/auth-response-headers: x-auth-userinfo, X-Auth-Userinfo
#      traefik.ingress.kubernetes.io/rate-limit: |
#        extractorfunc: client.ip
#        rateset:
#          api-rateset:
#            period: 1s
#            average: 10
#            burst: 20


# ----------------------------------------------------------------------
# DFR3 SERVICE CONFIGURATION
# ----------------------------------------------------------------------
svc_dfr3:
  replicas: 4
  image:
    repository: dfr3-jetty
    tag: 1.13.2
  service:
    type: ClusterIP
    port: 8888
  ingress:
    annotations:
#      ingress.kubernetes.io/auth-url: /auth/
#      ingress.kubernetes.io/auth-response-headers: x-auth-userinfo, X-Auth-Userinfo
#      traefik.ingress.kubernetes.io/rate-limit: |
#        extractorfunc: client.ip
#        rateset:
#          api-rateset:
#            period: 1s
#            average: 10
#            burst: 20

# ----------------------------------------------------------------------
# HAZARD SERVICE CONFIGURATION
# ----------------------------------------------------------------------
svc_hazard:
  replicas: 4
  image:
    repository: hazard-jetty
    tag: 1.13.2
  service:
    type: ClusterIP
    port: 8888
  ingress:
    annotations:
#      ingress.kubernetes.io/auth-url: /auth/
#      ingress.kubernetes.io/auth-response-headers: x-auth-userinfo, X-Auth-Userinfo
#      traefik.ingress.kubernetes.io/rate-limit: |
#        extractorfunc: client.ip
#        rateset:
#          api-rateset:
#            period: 1s
#            average: 10
#            burst: 20

# ----------------------------------------------------------------------
# SPACE SERVICE CONFIGURATION
# ----------------------------------------------------------------------
svc_space:
  replicas: 2
  image:
    repository: space-jetty
    tag: 1.13.2
  service:
    type: ClusterIP
    port: 8888
  ingress:
    annotations:
#      ingress.kubernetes.io/auth-url: /auth/
#      ingress.kubernetes.io/auth-response-headers: x-auth-userinfo, X-Auth-Userinfo
#      traefik.ingress.kubernetes.io/rate-limit: |
#        extractorfunc: client.ip
#        rateset:
#          api-rateset:
#            period: 1s
#            average: 10
#            burst: 20

# ----------------------------------------------------------------------
# SEMANTICS SERVICE CONFIGURATION
# ----------------------------------------------------------------------
svc_sema:
  replicas: 1
  image:
    repository: semantics-jetty
    tag: 1.13.2
  service:
    type: ClusterIP
    port: 8888
  ingress:
    annotations:
#      ingress.kubernetes.io/auth-url: /auth/
#      ingress.kubernetes.io/auth-response-headers: x-auth-userinfo, X-Auth-Userinfo
#      traefik.ingress.kubernetes.io/rate-limit: |
#        extractorfunc: client.ip
#        rateset:
#          api-rateset:
#            period: 1s
#            average: 10
#            burst: 20

# ----------------------------------------------------------------------
# MAESTRO SERVICE CONFIGURATION
# ----------------------------------------------------------------------
svc_maestro:
  password: password
  common:
    image:
      repository: maestro
      tag: 1.0.0
      pullPolicy: IfNotPresent
    service:
      type: ClusterIP
      port: 8000
  testbeds:
    slc:
      enabled: true
      env:
        host: incore-postgresql-headless
        port: 5432
        user: user
        password: password
        db_name: maestro_slc
        prefix: /maestro/slc
        workers: 2
      replicas: 1
    joplin:
      enabled: true
      env:
        host: incore-postgresql-headless
        port: 5432
        user: user
        password: password
        db_name: maestro_joplin
        prefix: /maestro/joplin
        workers: 2
      replicas: 1
    galveston:
      enabled: true
      env:
        host: incore-postgresql-headless
        port: 5432
        user: user
        password: password
        db_name: maestro_galveston
        prefix: /maestro/galveston
        workers: 2
      replicas: 1

# ----------------------------------------------------------------------
# PLOTTING SERVICE CONFIGURATION
# ----------------------------------------------------------------------
svc_plotting:
  replicas: 1
  image:
    repository: plotting
    tag: 1.11.0
  service:
    type: ClusterIP
    port: 5000
  ingress:
    annotations:
  persistence:
    enabled: true
    size: 5Gi

# ----------------------------------------------------------------------
# LDAP CONFIGURATION
# ----------------------------------------------------------------------
# used to get groups the user belongs to to give access to spaces etc.
ldap:
  url: ldap.example.com
  userdn: "OU=People,OU=example,OU=com"
  admins: admin
  refresh: "900"
  viewall: vieall

# ----------------------------------------------------------------------
# PLAYBOOK CONFIGURATION
# ----------------------------------------------------------------------
playbooks:
  slc:
    enabled: true
    image:
      repository: playbook/slc
      tag: 0.2.2
    replicas: 1
  joplin:
    enabled: true
    image:
      repository: playbook/joplin
      tag: 0.1.1
    replicas: 1
  galveston:
    enabled: true
    image:
      repository: playbook/galveston
      tag: 0.1.1
    replicas: 1

# ----------------------------------------------------------------------
# DATAWOLF CONFIGURATION
# ----------------------------------------------------------------------
datawolf:
  image:
    repository: hub.ncsa.illinois.edu/incore/datawolf
    tag: 1.10.0

  auth:
    enabled: false
    admins:
      - datawolf@incore.illinios.edu

  dataset: public

  loglevel: INFO

  engine:
    storelogs: true

  persistence:
    #existingClaim:
    #storageClass: "-"
    size: 10Gi

  postgresql:
    enabled: false
    url: jdbc:postgresql://postgresql/datawolf
    postgresqlUsername: datawolf
    postgresqlPassword: datawolf
    postgresqlDatabase: database

  ingress:
    enabled: false

# ----------------------------------------------------------------------
# Usergroups sync configuration
# ----------------------------------------------------------------------
usergroups_sync:
  image:
    repository: usergroups-sync
    tag: 0.1.0

# ----------------------------------------------------------------------
# Maestro usersync configuration
# ----------------------------------------------------------------------
maestro_usersync:
  image:
    repository: maestro-usersync
    tag: 1.0.0
  env:
    REALM: "In-core"
    SERVER_BASE_URL: "url"
    TOKEN_URL: "url"
    ADMIN_USERNAME: "username"
    ADMIN_PASSWORD: "password"
    SLC_GROUP_ID: "slc_id"
    JOPLIN_GROUP_ID: "joplin_id"
    GALVESTON_GROUP_ID: "galveston_id"
    NCSA_DEVELOPER_LIST: "developers"

# ----------------------------------------------------------------------
# DEPENDENCIES CONFIGURATION
# ----------------------------------------------------------------------

# ----------------------------------------------------------------------
# GEOSERVER CONFIGURATION
# ----------------------------------------------------------------------
geoserver:
  enabled : true
  username: admin
  password: incorerocks
  workspace: incore
  url: http://incore-geoserver:8080/geoserver/
  replicas: 1
  image:
    repository: kartoza/geoserver
    tag: 2.17.2
  service:
    type: ClusterIP
    port: 8080
  persistence:
    #existingClaim:
    size: 2Ti

# ----------------------------------------------------------------------
# JUPYTERHUB
# ----------------------------------------------------------------------
jupyterhub:
  hub:
    image:
      name: hub.ncsa.illinois.edu/incore/hub
      tag: 0.6.0
      pullSecrets:
        - regcred
    baseUrl: /hub/
    extraEnv:
      JUPYTER_ENABLE_LAB: "1"
      KEYCLOAK_AUDIENCE: INCORE
      KEYCLOAK_HOSTNAME: incore.example.com
      KEYCLOAK_REALM: In-core
      AUTH_GROUP: incore_user
      AUTH_ROLE: incore_user
    extraConfig:
      incoreConfig.py: |
        from customauthenticator.custom import CustomTokenAuthenticator
        c.Spawner.cmd = ['start.sh', 'jupyterhub-singleuser', '--allow-root']
        c.KubeSpawner.args = ['--allow-root']
        c.JupyterHub.authenticator_class = CustomTokenAuthenticator
        c.CustomTokenAuthenticator.keycloak_url = "https://%s/auth/realms/%s/" % (os.getenv('KEYCLOAK_HOSTNAME'), os.getenv('KEYCLOAK_REALM'))
        c.CustomTokenAuthenticator.auth_cookie_header= "Authorization"
        c.CustomTokenAuthenticator.auth_username_key= "preferred_username"
        c.CustomTokenAuthenticator.auth_uid_number_key = "uid_number"
        c.CustomTokenAuthenticator.enable_auth_state = True
        c.CustomTokenAuthenticator.auto_login = True
        c.CustomTokenAuthenticator.auth_group = os.getenv('AUTH_GROUP')
        c.CustomTokenAuthenticator.auth_role = os.getenv('AUTH_ROLE')
        c.CustomTokenAuthenticator.landing_page_login_url = "https://" + os.getenv('KEYCLOAK_HOSTNAME')
    extraVolumes:
      - name: incore
        configMap:
          name: incore
          defaultMode: 420
    extraVolumeMounts:
      - name: incore
        mountPath: /etc/quota.json
        subPath: quota.json
  scheduling:
    userScheduler:
      enabled: false
  singleuser:
    defaultUrl: "/lab"
    image:
      name: hub.ncsa.illinois.edu/incore/lab
      tag: 4.1.0
      pullSecrets:
        - regcred
      command4: ["echo", "SUCCESS"]
    # need root to allow to change 
    uid: 0
    fsGid: 0
    # mount to user home directorys
    storage:
      homeMountPath: /home/{username}
    extraEnv:
      CHOWN_HOME: 'yes'
      INCORE_SERVER: incore.ncsa.illinois.edu
    #storage:
    #  type: dynamic
    #  capacity: 2Gi
    #  requests: 1Gi
    #  limit: 2Gi
    #  dynamic:
    #    storageClass: nfs-client
  ingress:
    enabled: true
    hosts:
      - incore.example.com

# ----------------------------------------------------------------------
# MONGODB
# ----------------------------------------------------------------------
mongodb:
  architecture: standalone
  useStatefulSet: true
  auth:
    rootPassword: incorerocks
  replicaSetName: incore
  initdbScripts:

# ----------------------------------------------------------------------
# POSTGRESQL
# ----------------------------------------------------------------------
postgresql:
  postgresqlPassword: incorerocks

  initdbScripts:
    keycloak.sql: |
      CREATE DATABASE keycloak;
      CREATE USER keycloak WITH PASSWORD 'keycloak';
      GRANT ALL PRIVILEGES ON DATABASE keycloak TO keycloak;
    datawolf.sql: |
      CREATE DATABASE datawolf;
      CREATE USER datawolf WITH PASSWORD 'datawolf';
      GRANT ALL PRIVILEGES ON DATABASE datawolf TO datawolf;
    maestro.sql: |
      CREATE DATABASE maestro_galveston;
      CREATE DATABASE maestro_joplin;
      CREATE DATABASE maestro_slc;
      CREATE USER maestro WITH PASSWORD 'maestro';
      GRANT ALL PRIVILEGES ON DATABASE maestro_galveston TO maestro;
      GRANT ALL PRIVILEGES ON DATABASE maestro_joplin TO maestro;
      GRANT ALL PRIVILEGES ON DATABASE maestro_slc TO maestro;

# ----------------------------------------------------------------------
# KEYCLOAK
# ----------------------------------------------------------------------
keycloak:
  user: keycloak
  password: keycloak
  postgresql:
    enabled: false
  ingress:
    tls: []
    enabled: true
    servicePort: http
    hosts:
      - incore.example.com
    rules:
      - host: incore.example.com
        paths:
          - path: /auth/
            pathType: ImplementationSpecific
  extraEnv: |
    - name: PROXY_ADDRESS_FORWARDING
      value: "true"
    - name: KEYCLOAK_USER
      value: keycloak
    - name: KEYCLOAK_PASSWORD
      value: keycloak
    - name: DB_VENDOR
      value: postgres
    - name: DB_ADDR
      value: incore-postgresql
    - name: DB_PORT
      value: "5432"
    - name: DB_DATABASE
      value: keycloak
    - name: DB_USER
      value: keycloak
    - name: DB_PASSWORD
      value: keycloak

